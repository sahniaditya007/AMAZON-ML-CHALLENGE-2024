{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget https://s3-ap-southeast-1.amazonaws.com/he-public-data/datasetb2d9982.zip\n",
    "\n",
    "# Unzip the dataset\n",
    "!unzip datasetb2d9982.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install torch transformers pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (assume the files inside the zip have these names)\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for text columns in train and test data\n",
    "train_data['TITLE'] = train_data['TITLE'].fillna('')\n",
    "train_data['DESCRIPTION'] = train_data['DESCRIPTION'].fillna('')\n",
    "train_data['BULLET_POINTS'] = train_data['BULLET_POINTS'].fillna('')\n",
    "\n",
    "# Handle missing categorical values\n",
    "train_data['PRODUCT_TYPE_ID'] = train_data['PRODUCT_TYPE_ID'].fillna(train_data['PRODUCT_TYPE_ID'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        product = self.data.iloc[idx]\n",
    "        title = product['TITLE']\n",
    "        description = product['DESCRIPTION']\n",
    "        bullet_points = product['BULLET_POINTS']\n",
    "        product_type = product['PRODUCT_TYPE_ID']\n",
    "        length = product['PRODUCT_LENGTH']\n",
    "\n",
    "        # Concatenate text data\n",
    "        text = title + ' ' + description + ' ' + bullet_points\n",
    "        \n",
    "        # Tokenize text data\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'product_type': torch.tensor(product_type, dtype=torch.long),\n",
    "            'length': torch.tensor(length, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "train_dataset = ProductDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductLengthPredictor(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        super(ProductLengthPredictor, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc1 = nn.Linear(768 + 1, 128)  # 768 from DistilBERT output + 1 for product_type\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, product_type):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.last_hidden_state[:, 0]  # Take [CLS] token output\n",
    "        x = torch.cat((pooled_output, product_type.unsqueeze(1)), dim=1)  # Concatenate with product type\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load pre-trained DistilBERT model\n",
    "bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model and move it to the GPU if available\n",
    "model = ProductLengthPredictor(bert_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with validation\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        product_type = batch['product_type'].to(device, dtype=torch.float)\n",
    "        length = batch['length'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, product_type)\n",
    "        loss = criterion(outputs.squeeze(), length)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test dataset\n",
    "test_dataset = ProductDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        product_type = batch['product_type'].to(device, dtype=torch.float)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, product_type)\n",
    "        predictions.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "# Store predictions\n",
    "test_data['PREDICTED_PRODUCT_LENGTH'] = predictions\n",
    "test_data[['PRODUCT_ID', 'PREDICTED_PRODUCT_LENGTH']].to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
